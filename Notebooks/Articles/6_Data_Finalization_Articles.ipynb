{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Chapter 1](#chapter1): Data Cleaning\n",
    "* [Chapter 2](#chapter2): Data Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: <a class=\"anchor\" id=\"chapter1\"></a> Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing required installations and downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "#Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#Date handling\n",
    "from datetime import datetime\n",
    "\n",
    "#Other\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppressing warnings\n",
    "warnings.simplefilter(action = \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in CSVs\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "df = pd.read_csv(\"Outputs/Articles/Snorkel/snorkel.csv\", index_col = 0, parse_dates = [\"pubtime\", \"pubday\", \"pubmonth\"])\n",
    "\n",
    "df_entities = pd.read_csv(\"Inputs/Articles/entities.csv\")\n",
    "df_media = pd.read_csv(\"Inputs/Articles/media.csv\", index_col = 0)\n",
    "df_key_media = pd.read_csv(\"Inputs/Articles/key_media.csv\", index_col = 0)\n",
    "df_key_entities = pd.read_csv(\"Inputs/Articles/key_entities.csv\", index_col = 0)\n",
    "os.chdir(\"Notebooks/Articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to clean text\n",
    "def clean_text(col_list):\n",
    "    for col in col_list:\n",
    "        try:\n",
    "            df[col] = df[col].apply(lambda x: x.replace(\"_\", \" \") if pd.notnull(x) else x)\n",
    "            df[col] = df[col].apply(lambda x: re.sub(r\"\\b(\\w+)( \\1\\b)+\", r\"\\1\", x) if pd.notnull(x) else x)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning sentence_ABSA, passage_ABSA, sentence_ABSA_rel_keywords, sentence_ABSA_subclause, clause_ABSA\n",
    "clean_text([\"sentence_ABSA\", \"passage_ABSA\", \"sentence_ABSA_rel_keywords\", \"sentence_ABSA_subclause\", \"clause_ABSA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing positive sentiment and mapping negative sentiment to -1\n",
    "df[\"sentiment\"] = df[\"sentiment\"].apply(lambda x: 0 if x == 1 else x) #for Snorkel df\n",
    "#df[\"sentiment\"] = df[\"sentiment\"].apply(lambda x: -1 if x == 1 else x) #for ML / DL dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping media names\n",
    "df[\"medium_name_mapped\"] = df[\"medium_name\"].apply(lambda x: x.replace(\"_\", \" \").replace(\"ae\", \"ä\").replace(\"oe\", \"ö\").replace(\"ue\", \"ü\").replace(\"aü\", \"aue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping entity names\n",
    "df[\"entity_name_mapped\"] = df[\"entity_name\"].apply(lambda x: x.replace(\"_\", \" \").replace(\"ae\", \"ä\").replace(\"oe\", \"ö\").replace(\"ue\", \"ü\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: <a class=\"anchor\" id=\"chapter2\"></a> Data Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting maps\n",
    "publisher_map = {medium: publisher for medium, publisher in zip(df_media[\"medium_name\"], df_media[\"publisher\"])}\n",
    "entity_group_map = {entity: group for entity, group in zip(df_entities[\"designed_entity\"], df_entities[\"associated_group\"])}\n",
    "entity_party_map = {entity: party for entity, party in zip(df_entities[\"designed_entity\"], df_entities[\"affiliated_party\"])}\n",
    "entity_type_map = {entity: type for entity, type in zip(df_entities[\"designed_entity\"], df_entities[\"entity_type\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying maps\n",
    "df[\"publisher\"] = df[\"medium_name\"].apply(lambda x: publisher_map[x])\n",
    "df[\"entity_group\"] = df[\"entity_name\"].apply(lambda x: entity_group_map[x])\n",
    "df[\"entity_party\"] = df[\"entity_name\"].apply(lambda x: entity_party_map[x])\n",
    "df[\"entity_type\"] = df[\"entity_name\"].apply(lambda x: entity_type_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns\n",
    "df.drop([\"index\", \"stratification\", \"sentence_ABSA_subclause\", \"sentence_ABSA_rel_keywords\", \"entity_keyword\"], \n",
    "        axis = 1, \n",
    "        inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving to CSV\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "df.to_csv(\"Outputs/Articles/df_final.csv\")\n",
    "os.chdir(\"Notebooks/Articles\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

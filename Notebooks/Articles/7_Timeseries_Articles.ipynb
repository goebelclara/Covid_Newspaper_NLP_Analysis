{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Chapter 1](#chapter1): Generating Timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: <a class=\"anchor\" id=\"chapter1\"></a> Generating Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Performing required installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "#Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "#Timeseries and date handling\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt \n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft, fftshift\n",
    "from math import factorial\n",
    "from astropy.convolution import convolve, Box1DKernel, Gaussian1DKernel, Trapezoid1DKernel\n",
    "\n",
    "#Stats\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats\n",
    "import math\n",
    "\n",
    "#Other\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppressing warnings\n",
    "warnings.simplefilter(action = \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in CSVs\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "df = pd.read_csv(\"Outputs/Articles/df_final.csv\", index_col = 0, parse_dates = [\"pubtime\", \"pubday\", \"pubmonth\"])\n",
    "\n",
    "df_entities = pd.read_csv(\"Inputs/Articles/entities.csv\")\n",
    "os.chdir(\"Notebooks/Articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ueli_Maurer',\n",
       " 'Guy_Parmelin',\n",
       " 'Ignazio_Cassis',\n",
       " 'Karin_Keller_Sutter',\n",
       " 'Simonetta_Sommaruga',\n",
       " 'Alain_Berset',\n",
       " 'Viola_Amherd',\n",
       " 'Bundesrat',\n",
       " 'Tanja_Stadler',\n",
       " 'Marcel_Tanner',\n",
       " 'Martin_Ackermann',\n",
       " 'Matthias_Egger',\n",
       " 'Taskforce',\n",
       " 'Christoph_Berger',\n",
       " 'EKIF',\n",
       " 'Stefan_Kuster',\n",
       " 'Pascal_Strupler',\n",
       " 'Virginie_Masserey',\n",
       " 'Anne_Levy',\n",
       " 'Patrick_Mathys',\n",
       " 'Marcel_Salathe',\n",
       " 'Daniel_Koch',\n",
       " 'BAG',\n",
       " 'Swissmedic',\n",
       " 'Lukas_Engelberger',\n",
       " 'GDK',\n",
       " 'SVP',\n",
       " 'SP',\n",
       " 'FDP',\n",
       " 'Die_Mitte',\n",
       " 'Die_Gruene',\n",
       " 'Gruenliberale',\n",
       " 'Juso',\n",
       " 'Befuerworter',\n",
       " 'Ja_Lager',\n",
       " 'Gegner',\n",
       " 'Leugner',\n",
       " 'Skeptiker',\n",
       " 'Kritiker',\n",
       " 'Opposition',\n",
       " 'Nein_Lager',\n",
       " 'Demonstranten',\n",
       " 'Freunde_Der_Verfassung',\n",
       " 'Mass_Voll']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting entities\n",
    "entities = list(df_entities[\"designed_entity\"].unique())\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20_Minuten',\n",
       " 'Basler_Zeitung',\n",
       " 'Swissinfo',\n",
       " 'SRF',\n",
       " 'Tages_Anzeiger',\n",
       " 'Berner_Zeitung',\n",
       " 'NZZ',\n",
       " 'Cash',\n",
       " 'Zuercher_Unterlaender',\n",
       " 'Blick',\n",
       " 'Der_Bund',\n",
       " 'Solothurner_Zeitung',\n",
       " 'Grenchner_Tagblatt',\n",
       " 'Aargauer_Zeitung',\n",
       " 'Werdenberger_&_Obertoggenburger',\n",
       " 'Urner_Zeitung',\n",
       " 'Appenzeller_Zeitung',\n",
       " 'Schweizer_Illustrierte',\n",
       " 'Handelszeitung',\n",
       " 'Thurgauer_Zeitung',\n",
       " 'Zuerichsee_Zeitung',\n",
       " 'Landbote',\n",
       " 'Zuger_Zeitung',\n",
       " 'Limmattaler_Zeitung',\n",
       " 'Luzerner_Zeitung',\n",
       " 'Langenthaler_Tagblatt',\n",
       " 'Zofinger_Tagblatt',\n",
       " 'Badener_Tagblatt',\n",
       " 'BZ_Basel',\n",
       " 'Oltner_Tagblatt',\n",
       " 'St._Galler_Tagblatt',\n",
       " 'Nidwaldner_Zeitung',\n",
       " 'Thuner_Tagblatt',\n",
       " 'Obwaldner_Zeitung',\n",
       " 'Berner_Oberlaender',\n",
       " 'Toggenburger_Tagblatt',\n",
       " 'Finanz_und_Wirtschaft',\n",
       " 'Thalwiler_Anzeiger',\n",
       " 'Die_Wochenzeitung',\n",
       " 'Beobachter',\n",
       " 'Bilanz',\n",
       " 'Schweizer_Familie',\n",
       " 'Glueckspost',\n",
       " 'Tele',\n",
       " 'TV_Star',\n",
       " 'Das_Magazin',\n",
       " 'Zuger_Presse',\n",
       " 'Zugerbieter']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting media\n",
    "media = list(df[\"medium_name\"].unique())\n",
    "media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to calculate kernel LOWESS smoothed sentiment of given entity and medium\n",
    "def calculate_kernel_lowess_smoothed_avg(df, entity, medium, interpolation_method, kernel, width, fraction, sentiment_col):\n",
    "    \"\"\"\n",
    "    This function calculates the smoothed sentiment via a selected kernel for a given entity and/or \n",
    "    newspaper, with additional LOWESS smoothing. If the user does not want to filter the sentiment by \n",
    "    entity and/or newspaper, the parameters should be set to False. If the user does not want to return \n",
    "    a specific sentiment column, the parameter should be set to False.\n",
    "    \"\"\"\n",
    "    #Filtering dataframe\n",
    "    if entity == False:\n",
    "        if medium == False:\n",
    "            df_filtered = df\n",
    "        else:\n",
    "            df_filtered = df[df[\"medium_name\"] == medium]\n",
    "    else:\n",
    "        if medium == False:\n",
    "            df_filtered = df[df[\"entity_name\"] == entity]\n",
    "        else:\n",
    "            df_filtered = df[(df[\"medium_name\"] == medium) & (df[\"entity_name\"] == entity)]\n",
    "    \n",
    "    #Setting indeces\n",
    "    indeces = pd.period_range(min(df_filtered[\"pubday\"]), max(df_filtered[\"pubday\"]))\n",
    "    indeces = indeces.to_timestamp()\n",
    "    \n",
    "    #Taking daily average, standard deviation, and sample size\n",
    "    avg = df_filtered.groupby(\"pubday\").mean()\n",
    "    avg.columns = [x + \"_avg\" for x in avg.columns]\n",
    "    std = df_filtered.groupby(\"pubday\").std()\n",
    "    std.columns = [x + \"_std\" for x in std.columns]\n",
    "    monthly_sample = df_filtered.groupby(\"pubmonth\").size()\n",
    "    monthly_sample.name = \"monthly_sample\"\n",
    "    \n",
    "    #Creating timeseries with interpolation\n",
    "    timeseries = pd.DataFrame(index = indeces)\n",
    "    timeseries = timeseries.join(avg).join(std)\n",
    "    timeseries = timeseries.interpolate(method = interpolation_method)\n",
    "    timeseries = timeseries.dropna()\n",
    "    \n",
    "    #Creating smoothed dataframe\n",
    "    df_smoothed = pd.DataFrame(index = timeseries.index)\n",
    "    \n",
    "    #Calculating convolution \n",
    "    for col in list(avg.columns) + list(std.columns):\n",
    "        smoothed_values = convolve(timeseries[col], kernel(width))\n",
    "        df_smoothed[col] = smoothed_values\n",
    "        \n",
    "    #Fitting LOWESS\n",
    "    lowess = sm.nonparametric.lowess\n",
    "    for col in list(avg.columns) + list(std.columns):\n",
    "        smoothed_values = lowess(df_smoothed[col].values, df_smoothed[col].index, is_sorted = True, frac = fraction)\n",
    "        smoothed_values = smoothed_values[:,1]\n",
    "        df_smoothed[col] = smoothed_values\n",
    "    \n",
    "    #Adding sample size\n",
    "    df_smoothed[\"pubmonth\"] = df_smoothed.index.strftime(\"%Y-%m\")\n",
    "    df_smoothed[\"pubmonth\"] = pd.to_datetime(df_smoothed[\"pubmonth\"])\n",
    "    df_smoothed = df_smoothed.join(monthly_sample, on = \"pubmonth\")\n",
    "    df_smoothed.drop(\"pubmonth\", axis = 1, inplace = True)\n",
    "    df_smoothed[\"monthly_sample\"] = df_smoothed[\"monthly_sample\"].fillna(0)\n",
    "    \n",
    "    #Dropping ID\n",
    "    df_smoothed.drop([\"id_avg\", \"id_std\"], axis = 1, inplace = True)\n",
    "    \n",
    "    #Returning information\n",
    "    if sentiment_col == False:\n",
    "        return df_smoothed\n",
    "    else:\n",
    "        return df_smoothed[[sentiment_col+\"_avg\", \"monthly_sample\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to save smoothed timeseries\n",
    "def generate_timeseries(func, kernel, width, fraction, df, sentiment_col, entities):\n",
    "    total_df = func(df, False, False, \"time\", kernel, width, fraction, sentiment_col)    \n",
    "    timeseries_df = pd.DataFrame(data = {\"total\": total_df[\"sentiment_avg\"], \"total_sample\": total_df[\"monthly_sample\"]})\n",
    "    for entity in entities:\n",
    "        entity_df = func(df, entity, False, \"time\", kernel, width, fraction, sentiment_col)\n",
    "        timeseries_df[entity] = entity_df[\"sentiment_avg\"]\n",
    "        timeseries_df[entity+\"_sample\"] = entity_df[\"monthly_sample\"]\n",
    "    return timeseries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicates\n",
    "df = df.drop_duplicates(subset = [\"sentence_ABSA\", \"entity_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating timeseries dataframes\n",
    "kernel_lowess_smoothed_df = generate_timeseries(calculate_kernel_lowess_smoothed_avg, Box1DKernel, 45, 0.075, df, \"sentiment\", entities)                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving to CSV\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "kernel_lowess_smoothed_df.to_csv(\"Outputs/Articles/df_kernel_lowess_timeseries_final.csv\")\n",
    "os.chdir(\"Notebooks/Articles\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
